{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI version is compatible.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from fastapi import FastAPI, HTTPException, Request, Depends,status\n",
    "from fastapi.responses import JSONResponse\n",
    "from pydantic import BaseModel\n",
    "from sqlmodel import SQLModel, Field, Session, create_engine, select\n",
    "import openai\n",
    "from packaging import version\n",
    "import functions\n",
    "from typing import Annotated\n",
    "\n",
    "# Check OpenAI version is correct\n",
    "required_version = version.parse(\"1.1.1\")\n",
    "current_version = version.parse(openai.__version__)\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')  # Use getenv to avoid KeyError if variable is not set\n",
    "if current_version < required_version:\n",
    "    raise ValueError(f\"Error: OpenAI version {openai.__version__} is less than the required version 1.1.1\")\n",
    "else:\n",
    "    print(\"OpenAI version is compatible.\")\n",
    "\n",
    "# Database model for logging queries and responses\n",
    "class QueryLog(SQLModel, table=True):\n",
    "    id: int = Field(default=None, primary_key=True)\n",
    "    user_query: str\n",
    "    assistant_response: str\n",
    "    timestamp: datetime = Field(default_factory=datetime.utcnow)\n",
    "\n",
    "class Location(SQLModel, table=True):\n",
    "    name: str = Field(index=True, primary_key=True)\n",
    "    location: str\n",
    "\n",
    "# Database setup\n",
    "database_url = \"DATABASE_URL\"  # Replace with your actual database URL\n",
    "engine = create_engine(database_url)\n",
    "\n",
    "def create_db_and_tables():\n",
    "    SQLModel.metadata.create_all(engine)\n",
    "\n",
    "# @asynccontextmanager\n",
    "def lifespan(app: FastAPI):\n",
    "    create_db_and_tables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing assistant ID.\n"
     ]
    }
   ],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "# @app.on_event(\"startup\")\n",
    "# def on_startup():\n",
    "#     create_db_and_tables()\n",
    "\n",
    "# Placeholder types for message content\n",
    "class ChatRequest(BaseModel):\n",
    "    thread_id: str  \n",
    "    message: str\n",
    "\n",
    "class ChatResponse(BaseModel):\n",
    "    response: str\n",
    "\n",
    "# Init OpenAI client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Create new assistant or load existing\n",
    "assistant_id = functions.create_assistant(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start_conversation():\n",
    "    thread = client.beta.threads.create()\n",
    "    thread_id = thread.id\n",
    "    print({\"thread_id\": thread_id})\n",
    "    return {\"thread_id\": thread_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_persons():\n",
    "    \"\"\"\n",
    "    Retrieves all persons from the database.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Location objects representing the persons.\n",
    "    \"\"\"\n",
    "    with Session(engine) as session:\n",
    "        loc_data = session.exec(select(Location)).all()\n",
    "        return loc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_person(person_data: Location):\n",
    "    \"\"\"\n",
    "    Creates a new person record in the database.\n",
    "\n",
    "    Args:\n",
    "        person_data (Location): name and location of person. \n",
    "\n",
    "    Returns:\n",
    "        Location: The created person record that is name and location of person. \n",
    "    \"\"\"\n",
    "    with Session(engine) as session:\n",
    "        session.add(person_data)\n",
    "        session.commit()\n",
    "        session.refresh(person_data)\n",
    "        return person_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_or_404(name:str)->Location:\n",
    "    with Session(engine) as session:\n",
    "        loc_data = session.exec(select(Location).where(Location.name == name)).first()\n",
    "        if not loc_data:\n",
    "            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f\"No location found for {name}\")\n",
    "        return loc_data\n",
    "    \n",
    "def get_person_location(name: str, location: Annotated[Location, Depends(get_location_or_404)]):\n",
    "    \"\"\"\n",
    "    Retrieve the location of a person by their name.\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the person.\n",
    "\n",
    "    Returns:\n",
    "        Location: The location of the person.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching location for {name}\")\n",
    "    \n",
    "    print(f\"Retrieved location data: {location}\")\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat(request: ChatRequest):\n",
    "    thread_id = request.thread_id\n",
    "    user_input = request.message\n",
    "    \n",
    "    if not thread_id:\n",
    "        return JSONResponse(content={\"Error\": \"Missing thread id\"}, status_code=400)\n",
    "\n",
    "    # Send the user message to the assistant thread\n",
    "    client.beta.threads.messages.create(thread_id=thread_id, role=\"user\", content=\"share me Harry's location\")\n",
    "    run = client.beta.threads.runs.create(thread_id=thread_id, assistant_id=assistant_id)\n",
    "    dict(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_bbjiO05ZL2MXogaAaDhd8ZkY', created_at=1708804320, metadata={}, object='thread')\n"
     ]
    }
   ],
   "source": [
    "from openai.types.beta.thread import Thread\n",
    "\n",
    "thread: Thread  = client.beta.threads.create()\n",
    "\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_vzNgX6c8y2d1n2rwEgurTNwn',\n",
       " 'assistant_id': None,\n",
       " 'content': [MessageContentText(text=Text(annotations=[], value='share the location of zia?'), type='text')],\n",
       " 'created_at': 1708804359,\n",
       " 'file_ids': [],\n",
       " 'metadata': {},\n",
       " 'object': 'thread.message',\n",
       " 'role': 'user',\n",
       " 'run_id': None,\n",
       " 'thread_id': 'thread_bbjiO05ZL2MXogaAaDhd8ZkY'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.types.beta.threads.thread_message import ThreadMessage\n",
    "\n",
    "# First Request\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"share the location of zia?\"\n",
    ")\n",
    "dict(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_o0EoP3Otfkzw4OwQH4QiYOBp',\n",
       " 'assistant_id': 'asst_NhaXiIu3IJjKIQ9g7AxNyY66',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': None,\n",
       " 'created_at': 1708804430,\n",
       " 'expires_at': 1708805030,\n",
       " 'failed_at': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': '\\n              The assistant will be responsible for communicating with the database to share locations of friends\\n              ',\n",
       " 'last_error': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo-0125',\n",
       " 'object': 'thread.run',\n",
       " 'required_action': None,\n",
       " 'started_at': None,\n",
       " 'status': 'queued',\n",
       " 'thread_id': 'thread_bbjiO05ZL2MXogaAaDhd8ZkY',\n",
       " 'tools': [ToolAssistantToolsFunction(function=FunctionDefinition(name='create_person', description='Create a new person record with name and location', parameters={'type': 'object', 'properties': {'name': {'type': 'string', 'description': 'The name of the person'}, 'location': {'type': 'string', 'description': 'The location of the person'}}, 'required': ['name', 'location']}), type='function'),\n",
       "  ToolAssistantToolsFunction(function=FunctionDefinition(name='get_person_location', description='Retrieve the location of a person by their name', parameters={'type': 'object', 'properties': {'name': {'type': 'string', 'description': 'The name of the person'}}, 'required': ['name']}), type='function'),\n",
       "  ToolAssistantToolsFunction(function=FunctionDefinition(name='read_all_persons', description='Get data of all persons in the database', parameters={'type': 'object', 'properties': {}, 'required': []}), type='function')],\n",
       " 'usage': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.types.beta.threads.run import Run\n",
    "\n",
    "run: Run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=\"asst_NhaXiIu3IJjKIQ9g7AxNyY66\"\n",
    ")\n",
    "dict(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions = {\n",
    "    \"read_all_persons\": read_all_persons,\n",
    "    \"create_person\": create_person,\n",
    "    \"get_person_location\": get_person_location\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thread_bbjiO05ZL2MXogaAaDhd8ZkY'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "#   # Loop until the run completes or requires action\n",
    "# while True:\n",
    "#     runStatus = client.beta.threads.runs.retrieve(thread_id=thread.id,\n",
    "#                                                   run_id=run.id)\n",
    "#     # Add run steps retrieval here for debuging\n",
    "#     run_steps = client.beta.threads.runs.steps.list(thread_id=thread.id, run_id=run.id)\n",
    "#     # show_json(\"Run Steps:\", run_steps)\n",
    "#     print(runStatus.status ,'.....')\n",
    "\n",
    "#     # This means run is making a function call   \n",
    "#     if runStatus.status == \"requires_action\":\n",
    "#         print(runStatus.status ,'.....')\n",
    "#         print(\"Status: \", \"requires_action\")\n",
    "#         show_json(\"submit_tool_outputs\", runStatus.required_action)\n",
    "#         if runStatus.required_action.submit_tool_outputs and runStatus.required_action.submit_tool_outputs.tool_calls:\n",
    "#             print(\"toolCalls present:\")\n",
    "#             toolCalls = runStatus.required_action.submit_tool_outputs.tool_calls\n",
    "\n",
    "#             tool_outputs = []\n",
    "#             for toolcall in toolCalls:\n",
    "#                 function_name = toolcall.function.name\n",
    "#                 function_args = json.loads(toolcall.function.arguments)\n",
    "                \n",
    "#                 if function_name in available_functions:\n",
    "                    \n",
    "                    \n",
    "#                     function_to_call = available_functions[function_name]\n",
    "#                     print(function_to_call,function_to_call.__name__==\"read_all_persons\",\"================================================================\")\n",
    "                  \n",
    "#                     if function_to_call.__name__ == \"read_all_persons\":\n",
    "                        \n",
    "#                         response = function_to_call\n",
    "                        \n",
    "                        \n",
    "#                         tool_outputs.append({\n",
    "#                                   \"tool_call_id\": toolcall.id,\n",
    "#                                   \"output\": response\n",
    "#                               })\n",
    "#                     elif function_to_call.__name__ == \"get_person_location\":\n",
    "#                         response = function_to_call(\n",
    "#                           name=function_args.get(\"name\")\n",
    "#                           )\n",
    "#                         tool_outputs.append({\n",
    "#                           \"tool_call_id\": toolcall.id,\n",
    "#                           \"output\": response,\n",
    "#                               })\n",
    "#                     elif function_to_call.__name__ == \"create_person\":\n",
    "#                         response = function_to_call(\n",
    "#                           name=function_args.get(\"name\")\n",
    "#                           location=function_args.get(\"location\")\n",
    "#                           )\n",
    "#                         tool_outputs.append({\n",
    "#                           \"tool_call_id\": toolcall.id,\n",
    "#                           \"output\": response,\n",
    "#                               })\n",
    "#             print(tool_outputs,\">>>>>\") \n",
    "#             # Submit tool outputs and update the run\n",
    "#             client.beta.threads.runs.submit_tool_outputs(\n",
    "#                 thread_id=thread.id,\n",
    "#                 run_id=run.id,\n",
    "#                 tool_outputs=tool_outputs)\n",
    "      \n",
    "#     elif runStatus.status == \"completed\":\n",
    "#         # List the messages to get the response\n",
    "#         print(\"completed...........logic\")\n",
    "#         messages: list[ThreadMessage] = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "#         for message in messages.data:\n",
    "#             role_label = \"User\" if message.role == \"user\" else \"Assistant\"\n",
    "#             message_content = message.content[0].text.value\n",
    "#             print(f\"{role_label}: {message_content}\\n\")\n",
    "#         break  # Exit the loop after processing the completed run\n",
    "\n",
    "#     elif run.status == \"failed\":\n",
    "#       print(\"Run failed.\")\n",
    "#       break\n",
    "\n",
    "#     elif run.status in [\"in_progress\", \"queued\"]:\n",
    "#       print(f\"Run is {run.status}. Waiting...\")\n",
    "#       time.sleep(5)  # Wait for 5 seconds before checking again\n",
    "\n",
    "#     else:\n",
    "#       print(f\"Unexpected status: {run.status}\")\n",
    "#       break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "06streamlitapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
